Prisma Puppet Project - Beginning Date: 10/11/2014
@Author: Alberto Di Savia Puglisi

This project's aim is to deploy a working openstack environment in one shot.
Of course it's a WORK IN PROGRESS and I really hope it will come to an end!

_______________________________________________________________________________

What does work:
  > Basic puppet settings
  > Hiera and librarian-puppet
  > Galera cluster of MariaDB database servers (3 to 5 nodes)
  > (2 or 3) Haproxy load balancers for the Galera cluster
  > HA of these load balancers through Keepalived
  > Openstack Users, DBs and Privileges entries
  > Rabbitmq cluster (3 to 5 nodes)
  
What should work better:
  > ssh exec.pp should give the ssh id_rsa to a puppetmaster or 
    something similar and the id_rsa.pub to other nodes 
  > hosts module should fit the hiera.yaml requirement
  > hiera variables are all in one single file
  > you tell me...  

Next steps:
  > GlusterFS cluster
  > ..
_______________________________________________________________________________

HOW-TO:

  1) Modify the /data/common.yaml file according to your needs.
  Here are some parameter to which you should pay attention:
    
    > galera_nodes -> the number of hosts the haproxy lb and the galera module 
      itself should consider (3, 4 or 5). 4 is the default value.

    > rabbit_nodes -> the number of hosts will form the rabbitmq cluster (3, 4 or 5). 
      3 is the default value.

    > haproxy_nodes -> the number of haproxy nodes. Choose between 2 and 3.

    > hap1_priority, hap2_priority, hap3_priority -> the priority of each 
      load balancer. 100, 101 and 102 are default values and should be ok.
  
    Keepalived decision about what server should take the virtual ip is taken
    considering the sum between two factors: the priority and the weight of
    each server. The weight is equal (by default) for each node but the
    priority is incremental (100 to 102 if there are 3 load balancers).
    Assuming they are only two, the server who gains the ip is the one that has
    the sum of 103 (priority 101 + weight 2) against the other that has sum 102
    (100+2). If the server earning the vip goes down, its weight becomes 0 thus
    his sum becomes 101 (101 + 0) and the less important load balancer (sum 102) takes
    the vip. When the maior server comes back to life, his weight is 103 and 
    it gains the vip again.
    
    Remember that if you change the number of hosts (galera_nodes, rabbit_nodes,..),
    you should provide at least an equivalent number of relative hostnames and ips!!!
  
  2) Edit the /manifests/nodes.pp to meet your requirements:
     > change the hostnames if needed.
  
  3) After you've completed the previous stages, run the following command 
    in order to apply your manifest: sh prisma/scripts/first_papply.sh
  
    This will download and install puppet, ruby and librarian-puppet and execute
    the custom puppet apply script. This script needs to be run just once.
  
    Please ignore the red warning (Warning: Setting templatedir is deprecated...). 
    It is an Ubuntu matter. It appears just once and then it is fixed by puppet. 

  4) Next time you wish to apply the manifest simply use the 'papply' command.

_______________________________________________________________________________

TROUBLESHOOTING:

  RabbitMQ cluster:
    > If, for any reason, you need to apply manifest of a rabbitmq node
      a second time, please exec the following command: killall -u rabbitmq
    > To verify the status of your cluster: rabbitmqctl cluster_status
_______________________________________________________________________________

If you have any question or suggestion, 
please feel free to contact me at alberto.disavia@ct.infn.it

                                     THAT'S ALL FOLKS
